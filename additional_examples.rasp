def _has_matching_end_token(seq) {
  sel_equal = select(seq, seq, ==);
  sel_all_backwards = select(indices, length - indices - 1, ==);
  sel_matching_tokens = sel_equal and sel_all_backwards;
  return aggregate(sel_matching_tokens, 1);
}

is_palindrome = count(_has_matching_end_token(tokens_str), 1) == length;


# Selects tokens until the first occurrence of the end_char
def substring_until_last(seq, end_char) {
	later = select(indices, indices, >);
	substring_sel = select(seq, end_char, ==) and later;
  substring_until = aggregate(substring_sel, 1);
  return substring_until * seq;
}

# Selects tokens starting from the first occurrence of the start_char
def substring_from_first(seq, start_char) {
	earlier = select(indices, indices, <);
	substring_sel = select(seq, start_char, ==) and earlier;
  substring_from = aggregate(substring_sel, 1);
  return substring_from * seq;
}

# Sequences need to be separated by separator token
def _check_are_anagrams(seq, sep) {
  seq_1 = substring_until_last(seq, sep);
	seq_1_sorted = sort(seq_1, seq_1);
  seq_2 = substring_from_first(seq, sep);
	seq_2_sorted = sort(seq_2, seq_2);
	matches = seq_1_sorted == seq_2_sorted;
  matches_count = count(matches, True);
  return matches_count == length;
}

are_anagrams = _check_are_anagrams(tokens, "#"); # only callable with the set example


def _count_unique_tokens(str) {
  earlier = select(str, str, ==) and select(indices, indices, <);
  first_occurrences = not aggregate(earlier, 1);
  return count(first_occurrences, True);
}

count_unique_tokens = _count_unique_tokens(tokens_str);


# Example for not being a lower bound for transformer architecture:
# A program without any select and aggregate, that compiles to a
# certain architecture, that can also be implemented using select
# and aggregate and therefore compiles into another architecture,
# consisting of different numbers of attention heads and layers.

# The (efficient) implementation without select & aggregate:
# Compiles to 1 layer, 1 attention head
def _count_vowels_efficient(tks) {
  is_vowel = tks in ["a", "e", "i", "o", "u", "A", "E", "I", "O", "U"];
  return count(is_vowel, True);
}
count_vowels_efficiently = _count_vowels_efficient(tokens);

# The (less efficient) implementation with select & aggregate:
# Compiles to 1 layer, 2 attention heads
def _count_vowels_inefficient(tks) {
  is_vowel = tks in ["a", "e", "i", "o", "u", "A", "E", "I", "O", "U"];
  is_vowel_binary = indicator(is_vowel);
  select_all = select(1, 1, ==);
  avg_vowels = aggregate(select_all, is_vowel_binary, 0);
  return avg_vowels * length;
}
count_vowels_inefficiently = _count_vowels_inefficient(tokens);